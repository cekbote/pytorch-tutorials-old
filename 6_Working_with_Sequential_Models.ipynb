{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Working with Sequential Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Articles used for this Tutorial\n",
    "\n",
    "- [Official PyTorch Tutorial](https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html)\n",
    "- [Official PyTorch Documentation](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)\n",
    "- [LSTMs In PyTorch](https://towardsdatascience.com/lstms-in-pytorch-528b0440244)\n",
    "- [Time Series Prediction using LSTM with PyTorch in Python](https://stackabuse.com/time-series-prediction-using-lstm-with-pytorch-in-python/)\n",
    "- [https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/]()\n",
    "- [LSTM Reference Card](https://www.gregcondit.com/articles/lstm-ref-card)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with an LSTM Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(3, 3)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = nn.LSTM(3,3) # Input dim is 3, output dim is 3\n",
    "lstm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a Sequence on length 5\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the hidden states\n",
    "hidden = (torch.zeros(1, 1, 3),\n",
    "          torch.zeros(1, 1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting to the example, note a few things. Pytorch’s LSTM expects all of its inputs to be 3D tensors. The semantics of the axes of these tensors is important. The first axis is the sequence itself, the second indexes instances in the mini-batch, and the third indexes elements of the input. We haven’t discussed mini-batching, so let’s just ignore that and assume we will always have just 1 dimension on the second axis. If we want to run the sequence model over the sentence “The cow jumped”, our input should look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([1, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0].size())\n",
    "print(inputs[0].view(1, 1, -1).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 1\n",
      "Input Shape : torch.Size([1, 3])\n",
      "H Shape : torch.Size([1, 1, 3])\n",
      "C Shape: torch.Size([1, 1, 3])\n",
      "Out Shape : torch.Size([1, 1, 3])\n",
      "Input : tensor([[ 1.0202,  2.0414, -0.8369]])\n",
      "H : tensor([[[-0.0651,  0.1030,  0.0016]]], grad_fn=<StackBackward>)\n",
      "C : tensor([[[-0.1387,  0.2331,  0.0077]]], grad_fn=<StackBackward>)\n",
      "Out : tensor([[[-0.0651,  0.1030,  0.0016]]], grad_fn=<StackBackward>)\n",
      "---------------------------------------\n",
      "Iteration : 2\n",
      "Input Shape : torch.Size([1, 3])\n",
      "H Shape : torch.Size([1, 1, 3])\n",
      "C Shape: torch.Size([1, 1, 3])\n",
      "Out Shape : torch.Size([1, 1, 3])\n",
      "Input : tensor([[-1.8159,  0.2232, -0.2229]])\n",
      "H : tensor([[[-0.1223,  0.0708,  0.0736]]], grad_fn=<StackBackward>)\n",
      "C : tensor([[[-0.4496,  0.2071,  0.1689]]], grad_fn=<StackBackward>)\n",
      "Out : tensor([[[-0.1223,  0.0708,  0.0736]]], grad_fn=<StackBackward>)\n",
      "---------------------------------------\n",
      "Iteration : 3\n",
      "Input Shape : torch.Size([1, 3])\n",
      "H Shape : torch.Size([1, 1, 3])\n",
      "C Shape: torch.Size([1, 1, 3])\n",
      "Out Shape : torch.Size([1, 1, 3])\n",
      "Input : tensor([[ 1.8058, -0.7358,  0.3719]])\n",
      "H : tensor([[[-0.0501,  0.0941,  0.0378]]], grad_fn=<StackBackward>)\n",
      "C : tensor([[[-0.0601,  0.5913,  0.2119]]], grad_fn=<StackBackward>)\n",
      "Out : tensor([[[-0.0501,  0.0941,  0.0378]]], grad_fn=<StackBackward>)\n",
      "---------------------------------------\n",
      "Iteration : 4\n",
      "Input Shape : torch.Size([1, 3])\n",
      "H Shape : torch.Size([1, 1, 3])\n",
      "C Shape: torch.Size([1, 1, 3])\n",
      "Out Shape : torch.Size([1, 1, 3])\n",
      "Input : tensor([[-0.7690,  0.3371, -1.1757]])\n",
      "H : tensor([[[-0.0660,  0.2091,  0.1333]]], grad_fn=<StackBackward>)\n",
      "C : tensor([[[-0.1699,  0.6061,  0.3343]]], grad_fn=<StackBackward>)\n",
      "Out : tensor([[[-0.0660,  0.2091,  0.1333]]], grad_fn=<StackBackward>)\n",
      "---------------------------------------\n",
      "Iteration : 5\n",
      "Input Shape : torch.Size([1, 3])\n",
      "H Shape : torch.Size([1, 1, 3])\n",
      "C Shape: torch.Size([1, 1, 3])\n",
      "Out Shape : torch.Size([1, 1, 3])\n",
      "Input : tensor([[0.4484, 1.6172, 1.2343]])\n",
      "H : tensor([[[-0.2193,  0.1993,  0.0046]]], grad_fn=<StackBackward>)\n",
      "C : tensor([[[-0.4893,  0.8654,  0.0258]]], grad_fn=<StackBackward>)\n",
      "Out : tensor([[[-0.2193,  0.1993,  0.0046]]], grad_fn=<StackBackward>)\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for inp in inputs:\n",
    "    out, hidden = lstm(inp.view(1, 1, -1), hidden)\n",
    "    print('Iteration : {}'.format(i+1))\n",
    "    print('Input Shape : {}'.format(inp.size()))\n",
    "    print('H Shape : {}'.format(hidden[0].size()))\n",
    "    print('C Shape: {}'.format(hidden[1].size()))\n",
    "    print('Out Shape : {}'.format(out.size()))\n",
    "    print('Input : {}'.format(inp))\n",
    "    print('H : {}'.format(hidden[0]))\n",
    "    print('C : {}'.format(hidden[1]))\n",
    "    print('Out : {}'.format(out))\n",
    "    print('---------------------------------------')\n",
    "    i = i + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# alternatively, we can do the entire sequence all at once.\n",
    "# the first value returned by LSTM is all of the hidden states throughout\n",
    "# the sequence. the second is just the most recent hidden state\n",
    "# (compare the last slice of \"out\" with \"hidden\" below, they are the same)\n",
    "# The reason for this is that:\n",
    "# \"out\" will give you access to all hidden states in the sequence\n",
    "# \"hidden\" will allow you to continue the sequence and backpropagate,\n",
    "# by passing it as an argument  to the lstm at a later time\n",
    "# Add the extra 2nd dimension\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "print(inputs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs\n",
      "tensor([[[ 1.0202,  2.0414, -0.8369]],\n",
      "\n",
      "        [[-1.8159,  0.2232, -0.2229]],\n",
      "\n",
      "        [[ 1.8058, -0.7358,  0.3719]],\n",
      "\n",
      "        [[-0.7690,  0.3371, -1.1757]],\n",
      "\n",
      "        [[ 0.4484,  1.6172,  1.2343]]])\n",
      "-----------\n",
      "Output:\n",
      "torch.Size([5, 1, 3])\n",
      "tensor([[[-0.0651,  0.1030,  0.0016]],\n",
      "\n",
      "        [[-0.1223,  0.0708,  0.0736]],\n",
      "\n",
      "        [[-0.0501,  0.0941,  0.0378]],\n",
      "\n",
      "        [[-0.0660,  0.2091,  0.1333]],\n",
      "\n",
      "        [[-0.2193,  0.1993,  0.0046]]], grad_fn=<StackBackward>)\n",
      "-----------\n",
      "Hidden\n",
      "(tensor([[[-0.2193,  0.1993,  0.0046]]], grad_fn=<StackBackward>), tensor([[[-0.4893,  0.8654,  0.0258]]], grad_fn=<StackBackward>))\n"
     ]
    }
   ],
   "source": [
    "print('Inputs')\n",
    "print(inputs)\n",
    "print('-----------')\n",
    "hidden = (torch.zeros(1, 1, 3), torch.zeros(1, 1, 3))  # clean out hidden state\n",
    "out, hidden = lstm(inputs, hidden)\n",
    "print('Output:')\n",
    "print(out.size())\n",
    "print(out)\n",
    "print('-----------')\n",
    "print('Hidden')\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Full LSTM CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size = 1, hidden_layer_size = 100, output_size = 1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size ),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size ))\n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        print(lstm_out.size())\n",
    "        print(len(input_seq))\n",
    "        print(lstm_out.view(len(input_seq), -1).size())\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(1, 100)\n",
       "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = torch.randn((10, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 100])\n",
      "10\n",
      "torch.Size([10, 100])\n"
     ]
    }
   ],
   "source": [
    "output = model(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n",
      "tensor([[-0.0140],\n",
      "        [-0.0017],\n",
      "        [-0.0080],\n",
      "        [-0.0166],\n",
      "        [-0.0062],\n",
      "        [-0.0129],\n",
      "        [-0.0073],\n",
      "        [-0.0129],\n",
      "        [-0.0080],\n",
      "        [-0.0017]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(output.size())\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Gradient Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y1, y2):\n",
    "    return torch.sum((y1-y2)*(y1-y2).t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = torch.rand(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "tensor(44.6129, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss1 = loss(y1, output)\n",
    "print(loss1.size())\n",
    "print(loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([400, 1])\n",
      "-------------------------------\n",
      "2\n",
      "torch.Size([400, 100])\n",
      "-------------------------------\n",
      "3\n",
      "torch.Size([400])\n",
      "-------------------------------\n",
      "4\n",
      "torch.Size([400])\n",
      "-------------------------------\n",
      "5\n",
      "torch.Size([1, 100])\n",
      "-------------------------------\n",
      "6\n",
      "torch.Size([1])\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for w in model.parameters():\n",
    "    print(i+1)\n",
    "    print(w.size())\n",
    "    i += 1\n",
    "    print('-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x0000029856324CF0>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 1])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n"
     ]
    }
   ],
   "source": [
    "print(model.lstm.weight_ih_l0.size())\n",
    "print(model.lstm.weight_hh_l0.size())\n",
    "print(model.lstm.bias_ih_l0.size())\n",
    "print(model.lstm.bias_hh_l0.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}