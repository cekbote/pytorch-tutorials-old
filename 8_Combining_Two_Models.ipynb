{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# Combining Two Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links Referred\n",
    "- [Combining Trained Models in PyTorch](https://discuss.pytorch.org/t/combining-trained-models-in-pytorch/28383)\n",
    "- [How the pytorch freeze network in some layers, only the rest of the training?](https://discuss.pytorch.org/t/how-the-pytorch-freeze-network-in-some-layers-only-the-rest-of-the-training/7088)\n",
    "- [Best practice for freezing layers?](https://discuss.pytorch.org/t/best-practice-for-freezing-layers/58156)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Two Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelA(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.f1 = nn.Linear(10, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.f1(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelB(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.f1 = nn.Linear(10, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.f1(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelC(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.f1 = nn.Linear(2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.f1(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, modela, modelb, modelc):\n",
    "        super().__init__()\n",
    "        self.modela = modela\n",
    "        self.modelb = modelb\n",
    "        self.modelc = modelc\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        out1 = self.modela(x1)\n",
    "        out2 = self.modelb(x2)\n",
    "        combined = out1 + out2\n",
    "        out = self.modelc(combined)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelA(\n",
      "  (f1): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "-------------\n",
      "ModelB(\n",
      "  (f1): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "-------------\n",
      "ModelC(\n",
      "  (f1): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "-------------\n",
      "CombinedModel(\n",
      "  (modela): ModelA(\n",
      "    (f1): Linear(in_features=10, out_features=2, bias=True)\n",
      "  )\n",
      "  (modelb): ModelB(\n",
      "    (f1): Linear(in_features=10, out_features=2, bias=True)\n",
      "  )\n",
      "  (modelc): ModelC(\n",
      "    (f1): Linear(in_features=2, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "model_a = ModelA()\n",
    "print(model_a.eval())\n",
    "print('-------------')\n",
    "\n",
    "model_b = ModelB()\n",
    "print(model_b.eval())\n",
    "print('-------------')\n",
    "\n",
    "model_c = ModelC()\n",
    "print(model_c.eval())\n",
    "print('-------------')\n",
    "\n",
    "model = CombinedModel(model_a, model_b, model_c)\n",
    "print(model.eval())\n",
    "print('-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n",
      "tensor([[1.3534]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "x_1 = torch.randn((1, 10))\n",
    "x_2 = torch.randn((1, 10))\n",
    "out = model(x_1, x_2)\n",
    "print(out.size())\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if the Gradients Backprpogates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = torch.randn((1, 1))\n",
    "loss = torch.sum((out1 - out) * (out1 - out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5345, -0.0671, -0.6861,  0.2198, -0.4625,  0.1486,  0.3617, -0.1481,\n",
      "         -0.4088,  0.2953],\n",
      "        [ 0.8029,  0.1009,  1.0307, -0.3301,  0.6948, -0.2232, -0.5434,  0.2225,\n",
      "          0.6142, -0.4436]])\n",
      "tensor([-0.4151,  0.6236])\n",
      "tensor([[ 0.2569,  0.3994, -0.1701,  0.3060,  0.5866,  0.1089, -0.6538, -0.1235,\n",
      "         -0.4634,  0.6891],\n",
      "        [-0.3860, -0.5999,  0.2555, -0.4597, -0.8813, -0.1637,  0.9821,  0.1856,\n",
      "          0.6962, -1.0352]])\n",
      "tensor([-0.4151,  0.6236])\n",
      "tensor([[-0.5263,  1.0358]])\n",
      "tensor([1.0011])\n"
     ]
    }
   ],
   "source": [
    "for w in model.parameters():\n",
    "    print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking If you can Freeze Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = torch.randn((1, 10))\n",
    "x_2 = torch.randn((1, 10))\n",
    "out = model(x_1, x_2)\n",
    "out1 = torch.randn((1, 1))\n",
    "loss1 = torch.sum((out1 - out) * (out1 - out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing the layers in ModelB and ModelC\n",
    "\n",
    "for param in model.modela.parameters():\n",
    "    param.grad.zero_()\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.modelc.parameters():\n",
    "    param.grad.zero_()\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([0., 0.])\n",
      "tensor([[-0.4007,  0.3081, -0.3959,  0.2569, -0.8426, -0.7942,  1.0928, -0.8156,\n",
      "         -0.4102,  0.5447],\n",
      "        [ 0.6020, -0.4628,  0.5948, -0.3860,  1.2657,  1.1931, -1.6417,  1.2252,\n",
      "          0.6162, -0.8182]])\n",
      "tensor([-1.9246,  2.8912])\n",
      "tensor([[0., 0.]])\n",
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "for w in model.parameters():\n",
    "    print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2723,  0.2184, -0.1530, -0.1236,  0.3158,  0.0755, -0.0315,  0.0718,\n",
      "          0.0338, -0.1783],\n",
      "        [ 0.1576, -0.2730,  0.2558,  0.0843,  0.2682,  0.2816,  0.0759, -0.3078,\n",
      "          0.1048,  0.0202]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([[-0.2723,  0.2184, -0.1530, -0.1236,  0.3158,  0.0755, -0.0315,  0.0718,\n",
      "          0.0338, -0.1783],\n",
      "        [ 0.1576, -0.2730,  0.2558,  0.0843,  0.2682,  0.2816,  0.0759, -0.3078,\n",
      "          0.1048,  0.0202]])\n",
      "---------------\n",
      "Parameter containing:\n",
      "tensor([-0.1891,  0.0270])\n",
      "tensor([0., 0.])\n",
      "Parameter containing:\n",
      "tensor([-0.1891,  0.0270])\n",
      "---------------\n",
      "Parameter containing:\n",
      "tensor([[ 0.7708, -0.7561,  0.9680, -0.3373,  1.7980,  1.6047, -2.2810,  1.9434,\n",
      "          0.6652, -1.1358],\n",
      "        [-0.9095,  0.9213, -1.4506,  0.5033, -2.7141, -2.0701,  3.0423, -2.2158,\n",
      "         -1.2398,  1.3586]], requires_grad=True)\n",
      "tensor([[-0.4007,  0.3081, -0.3959,  0.2569, -0.8426, -0.7942,  1.0928, -0.8156,\n",
      "         -0.4102,  0.5447],\n",
      "        [ 0.6020, -0.4628,  0.5948, -0.3860,  1.2657,  1.1931, -1.6417,  1.2252,\n",
      "          0.6162, -0.8182]])\n",
      "Parameter containing:\n",
      "tensor([[ 1.1715, -1.0641,  1.3640, -0.5942,  2.6406,  2.3989, -3.3739,  2.7590,\n",
      "          1.0754, -1.6804],\n",
      "        [-1.5115,  1.3840, -2.0453,  0.8892, -3.9798, -3.2633,  4.6839, -3.4410,\n",
      "         -1.8560,  2.1768]], requires_grad=True)\n",
      "---------------\n",
      "Parameter containing:\n",
      "tensor([ 3.6990, -5.6540], requires_grad=True)\n",
      "tensor([-1.9246,  2.8912])\n",
      "Parameter containing:\n",
      "tensor([ 5.6236, -8.5453], requires_grad=True)\n",
      "---------------\n",
      "Parameter containing:\n",
      "tensor([[-0.4146,  0.6229]])\n",
      "tensor([[0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([[-0.4146,  0.6229]])\n",
      "---------------\n",
      "Parameter containing:\n",
      "tensor([0.4910])\n",
      "tensor([0.])\n",
      "Parameter containing:\n",
      "tensor([0.4910])\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for w in model.parameters():\n",
    "        print(w)\n",
    "        print(w.grad)\n",
    "        w -= w.grad\n",
    "        print(w)\n",
    "        print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if Multiple Outputs give you the Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, modela, modelb, modelc):\n",
    "        super().__init__()\n",
    "        self.modela = modela\n",
    "        self.modelb = modelb\n",
    "        self.modelc = modelc\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        out1 = self.modela(x1)\n",
    "        out2 = self.modelb(x2)\n",
    "        combined = out1 + out2\n",
    "        out = self.modelc(combined)\n",
    "        return combined, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelA(\n",
      "  (f1): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "-------------\n",
      "ModelB(\n",
      "  (f1): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "-------------\n",
      "ModelC(\n",
      "  (f1): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "-------------\n",
      "CombinedModel(\n",
      "  (modela): ModelA(\n",
      "    (f1): Linear(in_features=10, out_features=2, bias=True)\n",
      "  )\n",
      "  (modelb): ModelB(\n",
      "    (f1): Linear(in_features=10, out_features=2, bias=True)\n",
      "  )\n",
      "  (modelc): ModelC(\n",
      "    (f1): Linear(in_features=2, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "model_a = ModelA()\n",
    "print(model_a.eval())\n",
    "print('-------------')\n",
    "\n",
    "model_b = ModelB()\n",
    "print(model_b.eval())\n",
    "print('-------------')\n",
    "\n",
    "model_c = ModelC()\n",
    "print(model_c.eval())\n",
    "print('-------------')\n",
    "\n",
    "model_ = CombinedModel(model_a, model_b, model_c)\n",
    "print(model.eval())\n",
    "print('-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "x_1 = torch.randn((1, 10))\n",
    "x_2 = torch.randn((1, 10))\n",
    "combined, out = model_(x_1, x_2)\n",
    "print(combined.size())\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7363, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "combined1 = torch.rand((1, 2))\n",
    "out1 = torch.randn((1, 1))\n",
    "loss2 = torch.sum((combined1-combined) * (combined1-combined).t()) + torch.sum((out1 - out) * (out1 - out))\n",
    "print(loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss2.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing the layers in ModelB and ModelC\n",
    "\n",
    "for param in model_.modela.parameters():\n",
    "    param.grad.zero_()\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model_.modelc.parameters():\n",
    "    param.grad.zero_()\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([0., 0.])\n",
      "tensor([[-0.1662,  0.1188, -0.0749,  0.0866,  0.2091, -0.2654,  0.1461,  0.0766,\n",
      "          0.1266,  0.3058],\n",
      "        [-0.1266,  0.0905, -0.0571,  0.0660,  0.1593, -0.2022,  0.1113,  0.0583,\n",
      "          0.0964,  0.2329]])\n",
      "tensor([-0.1744, -0.1328])\n",
      "tensor([[0., 0.]])\n",
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "for w in model_.parameters():\n",
    "    print(w.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}